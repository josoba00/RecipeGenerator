services:

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama-data:/root/.ollama
    restart: unless-stopped

# To load the model into running container, execute this in terminal
# docker exec -it ollama ollama run llama2